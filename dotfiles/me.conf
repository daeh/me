centos_version=$(rpm -E "%{rhel}")

# export LD_LIBRARY_PATH=/home/daeda/me/dependencies/ncurses/lib:$LD_LIBRARY_PATH

source /usr/share/Modules/init/zsh ### load the 'module' command for the current shell

case $centos_version in
	7)
		module unload openmind8/gcc/12.2.0
		module load openmind/gcc/12.2.0
		;;
	8)
		module unload openmind/gcc/12.2.0
		module load openmind8/gcc/12.2.0
		;;
	*)
		printf "Unknown CentOS version: %s. Default settings will be applied.\n" $centos_version
		module unload openmind/gcc/12.2.0
		module load openmind8/gcc/12.2.0
		;;
esac

module load slurm

a=$(echo ${HOST:-$HOSTNAME} | shasum)
# export BULLETTRAIN_DIR_BG=#${a:0:6}
export TMUX_COLOR=#${a:0:6}

add_to_path_if_not_exists() {
	for dir in $(echo "$1" | tr ":" "\n"); do
		if [[ ":${PATH}:" != *":${dir}:"* ]]; then
			export PATH="${dir}:${PATH}"
		fi
	done
}

### Command aliases
alias o="/home/daeda/me/rmate/bin/rmate"
alias zshconfig="vim ~/.zshrc"

### srun alises
function interact_template () {
	echo "srun --constraint=rocky8 --cpus-per-task=6 --mem=25G --time=1-00:00:00 --pty zsh"
}
alias interact="srun --constraint=rocky8 --cpus-per-task=6 --mem=25G --time=1-00:00:00 --pty zsh"
alias interactlong="srun --constraint=rocky8 --cpus-per-task=6 --mem=25G --time=2-00:00:00 --pty zsh"
alias interactqos="srun --constraint=rocky8 --cpus-per-task=2 --mem=4G --time=1-00:00:00 --partition=gablab --pty zsh"
alias interactmin="srun --constraint=rocky8 --mem=4G --time=0-4:00:00 --pty zsh"
alias interactmid="srun --constraint=rocky8 --cpus-per-task=10 --mem=60G --time=1-12:00:00 --pty zsh"
alias interactmax="srun --constraint=rocky8 --cpus-per-task=16 --mem=100G --time=1-12:00:00 --pty zsh"
alias interactquick="srun --constraint=rocky8 --mem=60G -p om_bigmem --pty zsh" # time = 1h. If the requested time limit exceeds the partition's time limit, the job will be left in a PENDING state (possibly indefinitely). The default time limit is the partition's default time limit.
alias interactcam="srun --constraint=rocky8 --x11 --cpus-per-task=25 --mem=30G --time=1-12:00:00 --pty zsh"
alias interactcamheavy="srun --constraint=rocky8 --cpus-per-task=25 --mem=60G --time=1-12:00:00 --pty zsh"
alias interactcamquick="srun --constraint=rocky8 --cpus-per-task=25 --mem=60G -p om_bigmem --pty zsh" # time limit is 1h

# alias interact7="srun ... --cpus-per-task=6 --mem=25G --time=1-00:00:00 --pty zsh"
# alias interactlong7="srun ... --cpus-per-task=6 --mem=25G --time=2-00:00:00 --pty zsh"

### Slurm aliases
alias ssque='squeue --user=daeda --format="%32i %20j %.9P %.2t %.10M %.10l %.7C %.7m %R"' ###  %.6D %R
alias ssinfo='sinfo -N -o "%N, %c, %C, %e, %E, %G, %m, %T, %z"'
alias ssacctfin="sacct --format=jobid%20,jobname%30,ReqMem,maxrss,maxvmsize,maxpages,alloccpus,elapsed,exitcode,maxdiskread,maxdiskwrite,maxrssnode,state --units=G"

### Cluster location aliases
alias omhome="cd /om/user/daeda"
alias om2home="cd /om2/user/daeda"
alias mhhome="cd /mindhive/gablab/u/daeda"



############## functions


function tb_conda () {
	
	echo ''
	echo 'loading conda'

	# >>> conda initialize >>>
	# !! Contents within this block are managed by 'conda init' !!
	__conda_setup="$('/om/weka/gablab/daeda/software/miniconda3/bin/conda' 'shell.zsh' 'hook' 2> /dev/null)"
	if [ $? -eq 0 ]; then
		eval "$__conda_setup"
	else
		if [ -f "/om/weka/gablab/daeda/software/miniconda3/etc/profile.d/conda.sh" ]; then
			. "/om/weka/gablab/daeda/software/miniconda3/etc/profile.d/conda.sh"
		else
			add_to_path_if_not_exists "/om/weka/gablab/daeda/software/miniconda3/bin"
			# export PATH="/om/weka/gablab/daeda/software/miniconda3/bin:$PATH"
		fi
	fi
	unset __conda_setup
	# <<< conda initialize <<<

	echo ''
	echo ">>>conda version:"
	which conda
	conda -V

	conda activate omlab
}

function tb_latex () {
	
	echo ''
	echo 'loading latex'

	add_to_path_if_not_exists "/om2/user/daeda/software/texlive/bin/x86_64-linux"
	# export PATH="/om2/user/daeda/software/texlive/bin/x86_64-linux:$PATH"
	echo ''
	echo ''
}

function tb_matlab () {
	echo ''
	echo 'loading matlab functions'

	source /usr/share/Modules/init/zsh ### load the 'module' command for the current shell

	module add mit/matlab/2021b
	alias matlabcl="matlab -nodesktop -nosplash -nodisplay -singleCompThread"
	alias matlabclgreedy="matlab -nodesktop -nosplash -nodisplay"

	echo ''
	echo 'PATH:'
	echo "$PATH"
	echo ''
	echo ''
}

function tb_webppl () {
	echo ''
	echo 'loading webppl functions'

	echo ''
	echo 'loading NVM'

	export NVM_DIR="$HOME/.nvm"
	[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
	[ -s "$NVM_DIR/zsh_completion" ] && \. "$NVM_DIR/zsh_completion"  # This loads nvm zsh_completion

	case $centos_version in
		7)
			nvm use 17.0.0
			;;
		8)
			nvm use 20.15.1
			;;
		*)
			printf "Unknown CentOS version: %s. Default settings will be applied.\n" $centos_version
			nvm use 20.15.1
			;;
	esac
	

	echo ''
	echo 'loading node'

	# export PATH="/om/weka/gablab/daeda/software/node-v12.14.0-linux-x64/bin/:$PATH"

	echo ">>>node version:"
	npm version
	echo ">>>WebPPL version:"
	npm list -g webppl
	echo ">>>WebPPL version:"
	webppl --version

	echo ''
	echo 'PATH:'
	echo "$PATH"
	echo ''
	echo ''
}

function tb_fmriprep () {
	echo ''
	echo 'loading fmriprep functions'

	module add openmpi/gcc/64/1.8.1
	module add openmind/singularity/3.9.5  ### previously used 3.0.3

	echo "$PATH"
	echo ''
	echo ''
}

function tb_nipype () {
	source /usr/share/Modules/init/zsh ### load the 'module' command for the current shell

	tb_conda
	conda activate ve_nipip

	echo 'loading nipype functions'


	tb_matlab
	echo 'loading matlab'

	# Needed for nipype
	export SPM_PATH="/om2/user/daeda/software/spm12"
	
	### to run ANTS from fmriprep
	module add openmind/singularity/3.9.5

	# module add openmind/gcc/7.5.0
	# module add openmind/gcc/11.1.0
	module add openmind/ants/2.1.0-3.8bed08
	module add openmind/afni/2016.03.08
	module add openmind/slicer/4.11.0

	###SYSTEM FSL
	# module add openmind/fsl/5.0.9 

	###CUSTOM FSL
	# FSL Setup -- saxelab custom
	# FSLDIR=/om3/group/saxelab/software/fsl ### 6.0.3
	FSLDIR=/om2/user/daeda/software/fsl ### 6.0.4
	PATH=${FSLDIR}/bin:${PATH}
	export FSLDIR PATH
	. ${FSLDIR}/etc/fslconf/fsl.sh
	
	###SYSTEM freesurfer
	# module add openmind/freesurfer/6.0.0

	###CUSTOM freesurfer
	export FREESURFER_HOME=/om2/user/daeda/software/freesurfer ### 7.1.1
	### set SUBJECTS_DIR for the project
	# export SUBJECTS_DIR=$FREESURFER_HOME/subjects
	export FS_LICENSE='/gablab/p/ADHDER/data/adhder/code/license.txt'
	source $FREESURFER_HOME/SetUpFreeSurfer.sh
	echo "set default number of threads using:"
	echo "export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=2"
	echo ""
	echo "remember to >>   export SUBJECTS_DIR=<subjects_dir>   << before use"
	echo ""

	# echo "$PATH"
	# echo ''
	# echo ''

	function nicrash () {
		nipypecli crash ./crash-*.pklz(om[1])
	}
}



############## projects


### Project-specific location aliases
alias projadhd="cd /gablab/p/ADHDER/data/adhder"
alias projadhdb="cd /gablab/p/ADHDER/data/adhder/behavioral"
alias projadhdc="cd /gablab/p/ADHDER/data/adhder/code"
alias projadhdsource="cd /storage/gablab001/data/dicoms/adhder"

alias projiaa="cd /om/user/daeda/ite_iaa/ite_gb_inverseappraisal"
alias projiaac="cd /om/user/daeda/ite_iaa/ite_gb_inverseappraisal/code"
alias projiaadata="cd /om2/user/daeda/iaa_dataout"

PROJCAM="/home/daeda/itegb_cam"

alias projcam="cd ${PROJCAM}"
alias projcamcode="cd ${PROJCAM}/code"
alias projcamdata="cd /om2/user/daeda/iaa_dataout"

PROJCAMINVINV="/home/daeda/itegb_caminvinv"

function env_caminvinv () {
	# exit on error
	# set -e

	PROJHOME="${PROJCAMINVINV}"

	alias phome="cd ${PROJHOME}"
	alias projhome="cd ${PROJHOME}"
	alias projcode="cd ${PROJHOME}/code"
	alias projdata="cd /om2/user/daeda/caminvinv_dataout"

	export PROJPATH="${PROJHOME}"

	tb_webppl
	tb_latex
	tb_conda

	conda activate caminvinv	

	cd "${PROJHOME}" || exit
}

function env_cam () {
	# exit on error
	# set -e

	export PROJCAMPATH="${PROJCAM}"

	tb_webppl
	tb_latex
	tb_conda

	conda activate ve_cam

	# Set directory aliases
	alias phome="cd ${PROJCAM}/code/"

	cd "${PROJCAM}/code" || exit
}


function env_adhder () {
	export SUBJECTS_DIR='/gablab/p/ADHDER/data/adhder/derivatives/freesurfer'
	# notifstr='freesurfer SUBJECTS_DIR set to ${SUBJECTS_DIR}'
	# echo "${notifstr}"
	
	tb_nipype
 
	alias phome="cd /gablab/p/ADHDER/data/adhder/"
	cd "/gablab/p/ADHDER/data/adhder" || exit
}

function env_fmriprep () {
	tb_fmriprep
	alias phome="cd /gablab/p/ADHDER/data/adhder/"
}

function launchkernel_caminvinv_tmux () {
	# "tmuxp_script.yaml in code/"
	# "calls launchkernel_caminvinv_interactive()"
	# "	links current logfile in .tmux_temp_/current_remotelog.txt"
	# "	can be called with kernel_head()"
	# "calls sbatch launch_remote_kernel.sbatch in code/"
	# "	writes logs/jupyter-log-currenttunnel.txt"
	# "	can be called with kernel_follow()"
	
	tb_conda ### needed for tmuxp

	cd "${PROJCAMINVINV}/code/" || exit 

	tmux kill-session -t CAMINVINV-kernel

	tmuxp load ./tmuxp_script.yaml
}

function launchkernel_cam_tmux () {
	# "tmuxp_script.yaml in code/"
	# "calls launchkernel_cam_torch_interactive()"
	# "	links current logfile in .tmux_temp_/current_cam_remotelog.txt"
	# "	can be called with kernel_cam_head()"
	# "calls sbatch launch_remote_kernel_torch_interactive.sbatch in code/"
	# "	writes logs/jupyter-log-currenttunnel.txt"
	# "	can be called with kernel_cam_follow()"
	
	tb_conda ### needed for tmuxp

	cd "${PROJCAM}/code/" || exit 

	tmux kill-session -t CAM-torch-kernel

	tmuxp load ./tmuxp_script.yaml
}

function launchkernel_caminvinv_interactive () {
	cd "${PROJHOME}/code/" || exit 

	partit='gablab'
	vared -p "partition (gablab|om_bigmem|-none-): " partit

	time='2-00:00:00'
	vared -p "time: " time

	ncpu=6
	vared -p "cpus-per-task: " ncpu

	mem=25
	vared -p "mem: " mem

	print "Intel Xeon E5 : dgx001,dgx002,node017,node[031-077]"
	print "Intel Xeon Gold : node[078-094,097,098]"
	print "AMD Centos 8 : node[100-116]"
	excludenode="node[031,081,086,100-116]"
	vared -p "excludenode: " excludenode

	jobname='juptun_cam'
	vared -p "job-name: " jobname

	if [[ -z "${partit}" ]]; then
		partition=""
	else
		partition="--partition=${partit}"
	fi

	scriptfile='launch_remote_kernel.sbatch'

	print '> sbatch --constraint=rocky8 --job-name='$jobname' --cpus-per-task='$ncpu' --mem-per-cpu='${mem}'GB --time='$time' --exclude='"${excludenode}" $partition $scriptfile'\n'
	slurmout=$(sbatch --constraint=rocky8 --job-name=$jobname --cpus-per-task=$ncpu --mem-per-cpu=${mem}GB --time=$time --exclude="${excludenode}" $partition $scriptfile)

	print "sbatch returned: vvv"
	print "${slurmout}"
	print "sbatch returned: ^^^"
	print ""

	numeric_string_only=${slurmout//[^0-9]/}
	logfile="../logs/jupyter-log-${numeric_string_only}.txt"
	tmux_temp_dir="${PROJHOME}/logs/.tmux_temp_"
	logfilelink="${tmux_temp_dir}/current_cam_remotelog.txt"

	### store current logfile location
	if [[ ! -e $tmux_temp_dir ]]; then
		mkdir $tmux_temp_dir
	# elif [[ ! -d $dir ]]; then
	# 	echo "$Message" 1>&2
	fi

	echo "Waiting for ${logfile}   ..."
	while [[ ! -f "${logfile}" ]]; do
		printf "#"
		sleep 2
	done
	
	[[ -f "${logfilelink}" ]] && rm "${logfilelink}"
	ln "${logfile}" "${logfilelink}"

	print "\n>>> launchkernel_cam_torch_interactive launching sbatch $scriptfile <<<"
	# print "${logfile}"
	#echo "testln-- ${logfilelink}"
	print "logfile: ${logfile}\n-------------------\n"

	
	tail -f -n 70 "${logfile}"
}

function launchkernel_cam_torch_interactive () {
	cd "${PROJCAM}/code/" || exit 

	partit='gablab'
	vared -p "partition (gablab|om_bigmem|-none-): " partit

	time='2-00:00:00'
	vared -p "time: " time

	ncpu=6
	vared -p "cpus-per-task: " ncpu

	mem=25
	vared -p "mem: " mem

	print "Intel Xeon E5 : dgx001,dgx002,node017,node[031-077]"
	print "Intel Xeon Gold : node[078-094,097,098]"
	print "AMD Centos 8 : node[100-116]"
	excludenode="node[031,081,086,100-116]"
	vared -p "excludenode: " excludenode

	jobname='juptun_cam'
	vared -p "job-name: " jobname

	if [[ -z "${partit}" ]]; then
		partition=""
	else
		partition="--partition=${partit}"
	fi

	scriptfile='launch_remote_kernel_torch_interactive.sbatch'

	print '> sbatch --job-name='$jobname' --cpus-per-task='$ncpu' --mem-per-cpu='${mem}'GB --time='$time' --exclude='"${excludenode}" $partition $scriptfile'\n'
	slurmout=$(sbatch --job-name=$jobname --cpus-per-task=$ncpu --mem-per-cpu=${mem}GB --time=$time --exclude="${excludenode}" $partition $scriptfile)

	print "sbatch returned: vvv"
	print "${slurmout}"
	print "sbatch returned: ^^^"
	print ""

	numeric_string_only=${slurmout//[^0-9]/}
	logfile="../logs/jupyter-log-${numeric_string_only}.txt"
	tmux_temp_dir="${PROJCAM}/logs/.tmux_temp_"
	logfilelink="${tmux_temp_dir}/current_cam_remotelog.txt"

	### store current logfile location
	if [[ ! -e $tmux_temp_dir ]]; then
		mkdir $tmux_temp_dir
	# elif [[ ! -d $dir ]]; then
	# 	echo "$Message" 1>&2
	fi

	echo "Waiting for ${logfile}   ..."
	while [[ ! -f "${logfile}" ]]; do
		printf "#"
		sleep 2
	done
	
	[[ -f "${logfilelink}" ]] && rm "${logfilelink}"
	ln "${logfile}" "${logfilelink}"

	print "\n>>> launchkernel_cam_torch_interactive launching sbatch $scriptfile <<<"
	# print "${logfile}"
	#echo "testln-- ${logfilelink}"
	print "logfile: ${logfile}\n-------------------\n"

	
	tail -f -n 70 "${logfile}"
}

function kernel_cam_head () {
	tmux_temp_dir="${PROJCAM}/logs/.tmux_temp_"
	print "${tmux_temp_dir}/current_cam_remotelog.txt"
	head -n 40 "${tmux_temp_dir}/current_cam_remotelog.txt"
}

function kernel_head () {
	tmux_temp_dir="${PROJPATH}/logs/.tmux_temp_"
	print "${tmux_temp_dir}/current_remotelog.txt"
	head -n 40 "${tmux_temp_dir}/current_remotelog.txt"
}

function kernel_cam_follow () {
	tail -f "${PROJCAM}/logs/jupyter-log-currenttunnel.txt" || exit
}




function launchkernel_tmux_adhder () {
	# "tmuxp_script.yaml in code"
	# "calls launchkernel_adhder() from ~/.functions"
	# "	links current logfile in ~/.tmux_temp_/current_remotelog_adhder.txt"
	# "	can be called with launchkernel_head_adhder() from ~/.functions"
	# "calls sbatch launch_remote_kernel.sbatch in code"
	# "	writes ../logs/jupyter-log-currenttunnel.txt"
	# "	can be called with getssh_cam() from ~/.functions"

	tb_conda
	
	cd "/gablab/p/ADHDER/data/adhder/code/analysis/" || exit

	tmux kill-session -t adhdNipype-kernel

	tmuxp load ./tmuxp_script.yaml
}
function launchkernel_adhder () {
	cd "/gablab/p/ADHDER/data/adhder/code/analysis/" || exit
	slurmout="$(sbatch launch_remote_kernel.sbatch)"

	echo "sbatch returned: vvv"
	echo "${slurmout}"
	echo "sbatch returned: ^^^"
	echo ""

	numeric_string_only=${slurmout//[^0-9]/}
	logfile="../../logs_sbatch/jupyter-log-${numeric_string_only}.txt"
	tmux_temp_dir="/home/daeda/itegb_cam/logs/.tmux_temp_"
	logfilelink="${tmux_temp_dir}/current_remotelog_adhder.txt"

	### store current logfile location
	if [[ ! -e $tmux_temp_dir ]]; then
		mkdir $tmux_temp_dir
	# elif [[ ! -d $dir ]]; then
	# 	echo "$Message" 1>&2
	fi

	while ! [ -f "${logfile}" ]; do
		printf "#"
		sleep 2
	done
	
	#[[ -f "${logfilelink}" ]] && rm "${logfilelink}"
	#ln "${logfile}" "${logfilelink}"

	echo ""
	echo ">>> launchkernel_adhder launching sbatch launch_remote_kernel.sbatch <<<"
	echo "${logfile}"
	#echo "testln-- ${logfilelink}"
	echo "logfile: ${logfile}"
	tail -f -n 70 "${logfile}"
}



